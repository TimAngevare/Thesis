{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a3f6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import gc\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4fe343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mt-p-angevare\u001b[0m (\u001b[33mt-p-angevare-university-of-twente\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20260112_150350-27s35zzj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/t-p-angevare-university-of-twente/Qwen-fine-tuning/runs/27s35zzj' target=\"_blank\">14b-ioc-extraction</a></strong> to <a href='https://wandb.ai/t-p-angevare-university-of-twente/Qwen-fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/t-p-angevare-university-of-twente/Qwen-fine-tuning' target=\"_blank\">https://wandb.ai/t-p-angevare-university-of-twente/Qwen-fine-tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/t-p-angevare-university-of-twente/Qwen-fine-tuning/runs/27s35zzj' target=\"_blank\">https://wandb.ai/t-p-angevare-university-of-twente/Qwen-fine-tuning/runs/27s35zzj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/t-p-angevare-university-of-twente/Qwen-fine-tuning/runs/27s35zzj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f53a0f6a650>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Qwen-fine-tuning\", name=\"14b-ioc-extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "360cf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97352ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source_text', 'privacy_mask', 'id'],\n",
       "        num_rows: 29908\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source_text', 'privacy_mask', 'id'],\n",
       "        num_rows: 7946\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ai4privacy/pii-masking-300k\")\n",
    "dataset = dataset.filter(lambda x: x['language'] == 'English')\n",
    "dataset = dataset.select_columns([\"source_text\", \"privacy_mask\", \"id\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ceb6ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_entity_mapping = {\n",
    "    'USERNAME' : 'USERNAME',\n",
    "    'EMAIL' : 'EMAIL',\n",
    "    'LASTNAME1' : 'PERSON',\n",
    "    'IP' : 'IP',\n",
    "    'GIVENNAME1' : 'PERSON',\n",
    "    'TEL' : 'PHONE',\n",
    "    'CITY' : 'LOCATION',\n",
    "    'POSTCODE' : 'LOCATION',\n",
    "    'STREET': 'LOCATION',\n",
    "    'STATE' : 'LOCATION',\n",
    "    'BUILDING' : 'LOCATION',\n",
    "    'COUNTRY' : 'LOCATION',\n",
    "    'SECADDRESS' : 'LOCATION',\n",
    "    'LASTNAME2' : 'PERSON',\n",
    "    'GIVENNAME2' : 'PERSON',\n",
    "    'GEOCOORD' : 'LOCATION',\n",
    "    'LASTNAME3' : 'PERSON'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "04564bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entities(privacy_mask):\n",
    "    new_entities = []\n",
    "    for ent in privacy_mask:\n",
    "        if ent['label'] in dataset_entity_mapping.keys():\n",
    "            new_entities.append({\n",
    "                'type': dataset_entity_mapping.get(ent['label']),\n",
    "                'text' : ent['value'],\n",
    "                'start_pos' : ent['start'],\n",
    "                'end_pos' : ent['end']\n",
    "            })\n",
    "    return new_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60f4e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: {'privacy_mask': clean_entities(x['privacy_mask'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1e319409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_text': 'Subject: Group Messaging for Admissions Process\\n\\nGood morning, everyone,\\n\\nI hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developments and key information. Please find below the timeline for our upcoming meetings:\\n\\n- wynqvrh053 - Meeting at 10:20am\\n- luka.burg - Meeting at 21\\n- qahil.wittauer - Meeting at quarter past 13\\n- gholamhossein.ruschke - Meeting at 9:47 PM\\n- pdmjrsyoz1460 ',\n",
       " 'privacy_mask': [{'end_pos': 297,\n",
       "   'start_pos': 287,\n",
       "   'text': 'wynqvrh053',\n",
       "   'type': 'USERNAME'},\n",
       "  {'end_pos': 330, 'start_pos': 321, 'text': 'luka.burg', 'type': 'USERNAME'},\n",
       "  {'end_pos': 363,\n",
       "   'start_pos': 349,\n",
       "   'text': 'qahil.wittauer',\n",
       "   'type': 'USERNAME'},\n",
       "  {'end_pos': 416,\n",
       "   'start_pos': 395,\n",
       "   'text': 'gholamhossein.ruschke',\n",
       "   'type': 'USERNAME'},\n",
       "  {'end_pos': 453,\n",
       "   'start_pos': 440,\n",
       "   'text': 'pdmjrsyoz1460',\n",
       "   'type': 'USERNAME'}],\n",
       " 'id': '40767A'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d56659c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a cyber intelligence analyst with 20 years of experience in the the field.\n",
    "\n",
    "Your task is to extract any entity from the input text. For each entity found you MUST indicate the type in UPPERCASE. ONLY extract entities if literal entity is present in input text.\n",
    "The expected entity types are the following:\n",
    "\n",
    "- EMAIL: email addresses format (user@domain.tld)\n",
    "- IP: IP addresses (IPv4 x.x.x.x or IPv6)\n",
    "- BTC: ONLY Bitcoin wallet addresses (26-35 alphanumeric, starting with 1, 3, or bc1) EXCLUDE the word bitcoin or values (for example 2.0 BTC)\n",
    "- IBAN: iban bank account number\n",
    "- PERSON: Human names (John Smith, John, Catalina) EXCLUDE initials (for example A.H.) \n",
    "- LOCATION: cities, countries, geographic locations, regions\n",
    "- PHONE: phone numbers in any format\n",
    "- WEB_RESOURCE: URLs and web addresses EXCLUDE filenames\n",
    " \n",
    "**Output**:\n",
    "The output MUST be in a JSON object with key 'entities' and the value a list of dictionaries including every entity found. For each entity you MUST indicate the type in UPPERCASE.\n",
    "\n",
    "**OUTPUT EXAMPLE**:\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\"entity\": \"target123@darkmail.org\", \"type\": \"EMAIL\"},\n",
    "    {\"entity\": \"10.45.67.89\", \"type\": \"IP\"},\n",
    "    {\"entity\": \"Thompson\", \"type\": \"PERSON\"},\n",
    "    {\"entity\": \"Helsinki\", \"type\": \"LOCATION\"},\n",
    "    {\"entity\": \"Tim\", \"type\": \"PERSON\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Return empty array if no entities found in the input text.\n",
    "PAY ATTENTION to sentences that begin with entity type PERSON, for example Anna.\n",
    "PAY ATTENTION to when the sentences begin with possesive forms of entity type PERSON, for example Catalina's\n",
    "PAY ATTENTION to when the sentences contain a FULL NAME, the FULL NAME MUST be extracted as ONE entity.\n",
    "DO NOT include any entities from the example or the system prompt in your answer.\n",
    "\n",
    "**Verification**:\n",
    "1. profide your answer in valid JSON format.\n",
    "2. verify that all extracted entities are present in the input text.\n",
    "3. verify that no entities from the example or system prompt are included in your answer.\n",
    "4. verify that extracted entities match the expected formats for their types.\n",
    "5. provide your final revised andwer based on the verifications above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17e45961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd07e007a1c5497eb8ed9a105fe16509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446a185aa0cf4e89ac6b9150e3d2c8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c74adefc44ec89730d1703b599c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2245af7e23304791904cb61123a4b2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-14B\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8d907eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_to_chatml(source_text, privacy_mask):\n",
    "    # Convert to the JSON format expected by the prompt\n",
    "    entities_json = {\n",
    "        \"entities\": [\n",
    "            {\"entity\": ent['text'], \"type\": ent['type']} \n",
    "            for ent in privacy_mask\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": source_text},\n",
    "        {\"role\": \"assistant\", \"content\": json.dumps(entities_json, indent=2)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b2936c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd91adf94234acaa51d8023fb489486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29908 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739396e734c34597b0a0465030fff1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = dataset.map(lambda x: {\"messages\": convert_to_chatml(x['source_text'], x['privacy_mask'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "17bde313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5000\n",
      "Validation samples: 500\n"
     ]
    }
   ],
   "source": [
    "# Reduced dataset for faster training (~2-3 hours instead of 12+)\n",
    "train = dataset['train'].select(range(5000))  # 5k samples (was 30k)\n",
    "val = dataset['validation'].select(range(500))\n",
    "\n",
    "print(f\"Training samples: {len(train)}\")\n",
    "print(f\"Validation samples: {len(val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eb2a0ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Source Text (truncated) ===\n",
      "Subject: Group Messaging for Admissions Process\n",
      "\n",
      "Good morning, everyone,\n",
      "\n",
      "I hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developm...\n",
      "\n",
      "=== User Message (prompt + input) ===\n",
      "\n",
      "You are a cyber intelligence analyst with 20 years of experience in the the field.\n",
      "\n",
      "Your task is to extract any entity from the input text. For each entity found you MUST indicate the type in UPPERCASE. ONLY extract entities if literal entity is present in input text.\n",
      "The expected entity types are ...\n",
      "\n",
      "=== Assistant Response (with thinking tokens) ===\n",
      "Subject: Group Messaging for Admissions Process\n",
      "\n",
      "Good morning, everyone,\n",
      "\n",
      "I hope this message finds you well. As we continue our admissions processes, I would like to update you on the latest developments and key information. Please find below the timeline for our upcoming meetings:\n",
      "\n",
      "- wynqvrh053 - Meeting at 10:20am\n",
      "- luka.burg - Meeting at 21\n",
      "- qahil.wittauer - Meeting at quarter past 13\n",
      "- gholamhossein.ruschke - Meeting at 9:47 PM\n",
      "- pdmjrsyoz1460 ...\n",
      "\n",
      "=== Format: <think>reasoning</think> + JSON output ===\n"
     ]
    }
   ],
   "source": [
    "# verify format with thinking tokens\n",
    "example = train[0]\n",
    "print(\"=== Source Text (truncated) ===\")\n",
    "print(example['source_text'][:200] + \"...\")\n",
    "print(\"\\n=== User Message (prompt + input) ===\")\n",
    "print(example['messages'][0]['content'][:300] + \"...\")\n",
    "print(\"\\n=== Assistant Response (with thinking tokens) ===\")\n",
    "print(example['messages'][1]['content'][:500] + \"...\")\n",
    "print(\"\\n=== Format: <think>reasoning</think> + JSON output ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b196bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf51c16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592a83618f1c4be38d366776d25b4e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ce46a52f43462dba4003f3f1901abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c300f694c004306964b303e42f90fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c44bfece8f44b092e4d5157ca7a4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6acde905bd4c0b9f839c5d1d1ca35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920a6fee4f0a4a52b4f03e6c28dc3ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/1.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4182f1fc837d42ffa88ce7816fc58628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71304960ce58448fa2e72e0687bde16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21ac9850d8446f2a4c314febdc9964c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a90e31194f455c9549a4c3b0bb5dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0c10e1e85b45329f4d884366d1316e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574ffc6ec028436e827009d990d50299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f96e86053f4105ae250ecb1132237e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        use_cache=False\n",
    "    )\n",
    "\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67e195b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                   \n",
    "    lora_alpha=16,           \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dce7b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration for DeepSeek-R1-Distill-Qwen-14B:\n",
      "  - Train samples: 5000\n",
      "  - Epochs: 3\n",
      "  - Effective batch size: 16\n",
      "  - Learning rate: 1e-05\n",
      "  - Eval every 50 steps\n",
      "  - Max grad norm: 0.5\n",
      "  - Early stopping patience: 2 evals\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./sft_qwen_14b_output\",\n",
    "\n",
    "    num_train_epochs=3,                 \n",
    "    \n",
    "    max_length=512,\n",
    "    per_device_train_batch_size=1,       \n",
    "    gradient_accumulation_steps=16,      \n",
    "    \n",
    "\n",
    "    learning_rate=1e-5,                  \n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=0.5,                   \n",
    "    \n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,                      \n",
    "    \n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=3,\n",
    "    \n",
    "\n",
    "    packing=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"qwen-14b-pii\",\n",
    "    bf16=True,\n",
    "    optim=\"adamw_8bit\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    peft_config=lora_config,\n",
    "    processing_class=tokenizer,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(\n",
    "            early_stopping_patience=2,\n",
    "            early_stopping_threshold=0.005\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Training configuration for DeepSeek-R1-Distill-Qwen-14B:\")\n",
    "print(f\"  - Train samples: {len(train)}\")\n",
    "print(f\"  - Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  - Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  - Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  - Eval every {training_args.eval_steps} steps\")\n",
    "print(f\"  - Max grad norm: {training_args.max_grad_norm}\")\n",
    "print(f\"  - Early stopping patience: 2 evals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a60ea7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/939 13:06:21 < 22:10:56, 0.01 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.131500</td>\n",
       "      <td>2.115630</td>\n",
       "      <td>1.958243</td>\n",
       "      <td>409600.000000</td>\n",
       "      <td>0.577299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.971800</td>\n",
       "      <td>1.944338</td>\n",
       "      <td>2.058485</td>\n",
       "      <td>819200.000000</td>\n",
       "      <td>0.587022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.543400</td>\n",
       "      <td>1.468676</td>\n",
       "      <td>1.553811</td>\n",
       "      <td>1228800.000000</td>\n",
       "      <td>0.628149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>0.451372</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>1638400.000000</td>\n",
       "      <td>0.892368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.034833</td>\n",
       "      <td>2048000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>0.027035</td>\n",
       "      <td>2457600.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>2863104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=1.0126837648664202, metrics={'train_runtime': 47300.4894, 'train_samples_per_second': 0.317, 'train_steps_per_second': 0.02, 'total_flos': 2.405702904619991e+17, 'train_loss': 1.0126837648664202, 'epoch': 1.1184})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f2417ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./sft_qwen_14b_output/final_model\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./sft_qwen_14b_output/final_model\")\n",
    "print(\"Model saved to ./sft_qwen_14b_output/final_model\")\n",
    "\n",
    "# Log final metrics\n",
    "if wandb.run:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bd00623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    eval/loss  train/entropy  train/epoch  eval/entropy  \\\n",
      "0         NaN       1.284441        0.016           NaN   \n",
      "1         NaN       1.269152        0.032           NaN   \n",
      "2         NaN       1.277675        0.048           NaN   \n",
      "3         NaN       1.298521        0.064           NaN   \n",
      "4         NaN       1.296141        0.080           NaN   \n",
      "..        ...            ...          ...           ...   \n",
      "56        NaN       0.450221        0.768           NaN   \n",
      "57        NaN       0.438981        0.784           NaN   \n",
      "58        NaN       0.450000        0.800           NaN   \n",
      "59   0.418354            NaN        0.800       0.43036   \n",
      "60        NaN            NaN        0.800           NaN   \n",
      "\n",
      "    eval/steps_per_second    _timestamp  eval/num_tokens  train/num_tokens  \\\n",
      "0                     NaN  1.767459e+09              NaN          129032.0   \n",
      "1                     NaN  1.767460e+09              NaN          257738.0   \n",
      "2                     NaN  1.767461e+09              NaN          386236.0   \n",
      "3                     NaN  1.767462e+09              NaN          511714.0   \n",
      "4                     NaN  1.767462e+09              NaN          638004.0   \n",
      "..                    ...           ...              ...               ...   \n",
      "56                    NaN  1.767520e+09              NaN         6161836.0   \n",
      "57                    NaN  1.767521e+09              NaN         6289116.0   \n",
      "58                    NaN  1.767522e+09              NaN         6416551.0   \n",
      "59                  0.073  1.767524e+09        6416551.0               NaN   \n",
      "60                    NaN  1.767524e+09              NaN               NaN   \n",
      "\n",
      "    train/global_step  _step  eval/runtime  train/grad_norm  \\\n",
      "0                  10      0           NaN         0.251953   \n",
      "1                  20      1           NaN         0.263672   \n",
      "2                  30      2           NaN         0.281250   \n",
      "3                  40      3           NaN         0.277344   \n",
      "4                  50      4           NaN         0.296875   \n",
      "..                ...    ...           ...              ...   \n",
      "56                480     56           NaN         0.106445   \n",
      "57                490     57           NaN         0.108398   \n",
      "58                500     58           NaN         0.094238   \n",
      "59                500     59       1703.61              NaN   \n",
      "60                500     60           NaN              NaN   \n",
      "\n",
      "    train/learning_rate  train/mean_token_accuracy  train/loss  \\\n",
      "0          4.787234e-07                   0.634307      1.8155   \n",
      "1          1.010638e-06                   0.638439      1.7967   \n",
      "2          1.542553e-06                   0.635597      1.7983   \n",
      "3          2.074468e-06                   0.632969      1.8128   \n",
      "4          2.606383e-06                   0.635534      1.8003   \n",
      "..                  ...                        ...         ...   \n",
      "56         9.283624e-06                   0.904083      0.4442   \n",
      "57         9.234859e-06                   0.907369      0.4297   \n",
      "58         9.184626e-06                   0.904908      0.4402   \n",
      "59                  NaN                        NaN         NaN   \n",
      "60                  NaN                        NaN         NaN   \n",
      "\n",
      "    eval/samples_per_second  _runtime  eval/mean_token_accuracy  \n",
      "0                       NaN   4.77658                       NaN  \n",
      "1                       NaN   4.77658                       NaN  \n",
      "2                       NaN   4.77658                       NaN  \n",
      "3                       NaN   4.77658                       NaN  \n",
      "4                       NaN   4.77658                       NaN  \n",
      "..                      ...       ...                       ...  \n",
      "56                      NaN   4.77658                       NaN  \n",
      "57                      NaN   4.77658                       NaN  \n",
      "58                      NaN   4.77658                       NaN  \n",
      "59                    0.587   4.77658                  0.909308  \n",
      "60                      NaN   4.77658                       NaN  \n",
      "\n",
      "[61 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"/t-p-angevare-university-of-twente/transformer-fine-tuning/runs/rjx3lp23\")\n",
    "history = run.history()\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498a876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model for inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f41f5c108c497188514d63559e100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned LoRA adapters...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "import json\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "print(\"Loading base model for inference...\")\n",
    "inference_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Loading fine-tuned LoRA adapters...\")\n",
    "inference_model = PeftModel.from_pretrained(inference_model, \"./sft_14b_output/final_model\")\n",
    "inference_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yhw49tyyn3k",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_entities(text, max_new_tokens=512):\n",
    "    \"\"\"Run entity extraction on input text using the fine-tuned R1-Distill model.\"\"\"\n",
    "    \n",
    "    # Format as chat message - R1-Distill: no system prompt\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt + \"\\n\\nInput text:\\n\" + text}\n",
    "    ]\n",
    "    \n",
    "    # Tokenize\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(inference_model.device)\n",
    "    \n",
    "    # Generate with recommended R1-Distill settings\n",
    "    with torch.no_grad():\n",
    "        outputs = inference_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,  # Recommended for R1-Distill (0.5-0.7)\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    # Decode only the generated part\n",
    "    generated = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    response = tokenizer.decode(generated, skip_special_tokens=True)\n",
    "    \n",
    "    # Strip thinking tokens before parsing JSON\n",
    "    response_clean = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
    "    \n",
    "    # Try to parse as JSON\n",
    "    try:\n",
    "        # Find JSON in response\n",
    "        start = response_clean.find('{')\n",
    "        end = response_clean.rfind('}') + 1\n",
    "        if start != -1 and end > start:\n",
    "            result = json.loads(response_clean[start:end])\n",
    "            return result, response\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    return None, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ohw1yr4zvth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING FINE-TUNED MODEL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TEST 1\n",
      "================================================================================\n",
      "INPUT: Please contact John Smith at john.smith@company.com. The server IP is 192.168.1.100.\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2532: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTED ENTITIES (2 found):\n",
      "  - EMAIL: john.smith@company.com\n",
      "  - IP: 192.168.1.100\n",
      "\n",
      "================================================================================\n",
      "TEST 2\n",
      "================================================================================\n",
      "INPUT: Maria Garcia traveled from Madrid to New York last week.\n",
      "----------------------------------------\n",
      "EXTRACTED ENTITIES (3 found):\n",
      "  - PERSON: Maria Garcia\n",
      "  - LOCATION: Madrid\n",
      "  - LOCATION: New York\n",
      "\n",
      "================================================================================\n",
      "TEST 3\n",
      "================================================================================\n",
      "INPUT: Call me at +1-555-123-4567 or email support@example.org\n",
      "----------------------------------------\n",
      "EXTRACTED ENTITIES (2 found):\n",
      "  - PHONE: +1-555-123-4567\n",
      "  - EMAIL: support@example.org\n",
      "\n",
      "================================================================================\n",
      "TEST 4\n",
      "================================================================================\n",
      "INPUT: The suspect known as darkh4cker_99 was traced to IP 10.0.0.1 in Berlin, Germany.\n",
      "----------------------------------------\n",
      "EXTRACTED ENTITIES (3 found):\n",
      "  - PERSON: darkh4cker_99\n",
      "  - IP: 10.0.0.1\n",
      "  - LOCATION: Berlin\n",
      "\n",
      "================================================================================\n",
      "TESTING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test on various examples\n",
    "test_cases = [\n",
    "    # Test 1: Email and IP\n",
    "    \"Please contact John Smith at john.smith@company.com. The server IP is 192.168.1.100.\",\n",
    "    \n",
    "    # Test 2: Location and person  \n",
    "    \"Maria Garcia traveled from Madrid to New York last week.\",\n",
    "    \n",
    "    # Test 3: Phone number\n",
    "    \"Call me at +1-555-123-4567 or email support@example.org\",\n",
    "    \n",
    "    # Test 4: Mixed entities (username)\n",
    "    \"The suspect known as darkh4cker_99 was traced to IP 10.0.0.1 in Berlin, Germany.\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TESTING FINE-TUNED MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test_text in enumerate(test_cases):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TEST {i+1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"INPUT: {test_text[:200]}{'...' if len(test_text) > 200 else ''}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    result, raw_response = extract_entities(test_text)\n",
    "    \n",
    "    if result and 'entities' in result:\n",
    "        print(f\"EXTRACTED ENTITIES ({len(result['entities'])} found):\")\n",
    "        for ent in result['entities']:\n",
    "            print(f\"  - {ent.get('type', 'UNKNOWN')}: {ent.get('entity', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"RAW RESPONSE: {raw_response[:500]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TESTING COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3qhfxe7n4i7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with ground truth from validation set\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON WITH GROUND TRUTH (Validation Sample)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample = val[0]\n",
    "print(f\"\\nINPUT TEXT:\\n{sample['source_text'][:300]}...\")\n",
    "\n",
    "# Get model prediction\n",
    "result, _ = extract_entities(sample['source_text'])\n",
    "\n",
    "\n",
    "ground_truth = sample['privacy_mask']\n",
    "\n",
    "print(f\"\\n{'GROUND TRUTH':-^40}\")\n",
    "for ent in ground_truth[:10]: \n",
    "    print(f\"  - {ent['type']}: {ent['text']}\")\n",
    "if len(ground_truth) > 10:\n",
    "    print(f\"  ... and {len(ground_truth) - 10} more\")\n",
    "\n",
    "print(f\"\\n{'MODEL PREDICTION':-^40}\")\n",
    "if result and 'entities' in result:\n",
    "    for ent in result['entities'][:10]:\n",
    "        print(f\"  - {ent.get('type', 'UNKNOWN')}: {ent.get('entity', 'N/A')}\")\n",
    "    if len(result['entities']) > 10:\n",
    "        print(f\"  ... and {len(result['entities']) - 10} more\")\n",
    "else:\n",
    "    print(\"  No entities extracted or invalid JSON response\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
